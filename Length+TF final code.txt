from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

stop=set(stopwords.words('english'))
stri=""

with open("C:\\Users\\rahul\\OneDrive\\Desktop\\Web Scraper\\idf.txt") as f:
    data=f.readlines()
    for x in data:
        stri+=x;
    idf=word_tokenize(stri)
stri=""
import os
  
# Folder Path
path = "C:\\Users\\rahul\\OneDrive\\Desktop\\Web Scraper\\Database"
  
# Change the directory
os.chdir(path)

key =list()
# iterate through all file
for file in os.listdir():
    # Check whether file is in text format or not
    if file.endswith(".txt"):
        file_path = f"{path}\{file}"
        with open(file_path) as f:
            data =f.readlines()
            for x in data:
                val=x.strip()
                stri=stri+val
            tok=word_tokenize(stri)
            ans=list()
            for i in range(0,len(tok)):
                word=tok[i].lower()
                if word in stop:
                    pass
                elif word.isalpha():
                    ans.append(word)
                else:
                    pass
            none=""
            ans = list(map(lambda x: x.replace('\n',none).replace('\\n',none).replace(',',none),ans))
            for i in range(0,len(ans)):
                ans[i]=ans[i].lower()
                if ans[i]=='' or ans[i]=='.':
                    pass
                else:
                    key.append(ans[i])
            ans.clear()
            stri=""

key_final=list()

for i in key:
    if i in key_final:
        pass
    else:
        key_final.append(i)

key_final.sort()
key_len=list()
key.clear()
z=0
tf=list()
for file in os.listdir():
    # Check whether file is in text format or not
    if file.endswith(".txt"):
        file_path = f"{path}\{file}"
        with open(file_path) as f:
            data =f.readlines()
            for x in data:
                val=x.strip()
                stri=stri+val
            tok=word_tokenize(stri)
            ans=list()
            for i in range(0,len(tok)):
                word=tok[i].lower()
                if word in stop:
                    pass
                elif word.isalpha():
                    ans.append(word)
                else:
                    pass
            none=""
            ans = list(map(lambda x: x.replace('\n',none).replace('\\n',none).replace(',',none),ans))
            for i in range(0,len(ans)):
                ans[i]=ans[i].lower()
                if ans[i]=='' or ans[i]=='.':
                    pass
                else:
                    key.append(ans[i])
            ttf=list()
            for i in range(len(key_final)):
                st=""
                st=key_final[i]
                x=key.count(st)
                ttf.append(x)
            key_len.append(len(key))
            tf.append(ttf)
            z+=1
            ans.clear()
            key.clear()
            stri=""

#for i in range(len(tf)):
    #print(tf[i])
import math
tfidf=list()
mag=list()
sqsum=0
for i in range(len(tf)):
    for j in range(len(key_final)):
        sqsum+=tf[i][j]*tf[i][j]
    mag.append(math.sqrt(sqsum))
    sqsum=0

for i in range(len(tf)):
    for j in range(len(key_final)):
        if(tf[i][j])!=0:
            tfidf.append(str(i+1)+" "+str(j+1)+" "+str(tf[i][j]))

with open("length.txt","a+") as f:
    for x in key_len:
        f.write("%s\n" % x)

with open("tf.txt","a+") as f:
    for x in tfidf:
        f.write("%s\n" % x)
